{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3873e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpipe-art==0.5.0 langchain-core tenacity datasets vllm faiss-cpu chromadb requests lxml numpy transformers torch gql==3.4.1 peft \n",
    "# !pip install langchain-core tenacity datasets vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965eaa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from secretsConfig import oaiKey, wandbKey, openRouterKey  # Add openRouterKey\n",
    "\n",
    "# Required for RULER judge model\n",
    "os.environ[\"OPENAI_API_KEY\"] = oaiKey\n",
    "\n",
    "# Required for Weights & Biases\n",
    "os.environ[\"WANDB_API_KEY\"] = wandbKey\n",
    "\n",
    "# Required for OpenRouter (Gemini judge)\n",
    "os.environ[\"OPENROUTER_API_KEY\"] = openRouterKey  # ADD THIS LINE\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"OPENAI_API_KEY is required for RULER functionality.\")\n",
    "\n",
    "if not os.environ.get(\"WANDB_API_KEY\"):\n",
    "    raise ValueError(\"WANDB_API_KEY is required for W&B.\")\n",
    "\n",
    "if not os.environ.get(\"OPENROUTER_API_KEY\"):\n",
    "    raise ValueError(\"OPENROUTER_API_KEY is required for Gemini judge.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6c3f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IBM_Z_Datathon_RAG.semantic_search import FAISSSemanticSearch\n",
    "from IBM_Z_Datathon_RAG.KeywordSearch import keyword_search\n",
    "from IBM_Z_Datathon_RAG.ReadDocumentPart import read_document_part\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "535e659f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import random\n",
    "\n",
    "import art\n",
    "from art.serverless.backend import ServerlessBackend\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Declare the model - CHANGED TO QWEN3-14B\n",
    "model = art.TrainableModel(\n",
    "    name=\"legal-agent-001\",\n",
    "    project=\"legal-rag\",\n",
    "    base_model=\"Qwen/Qwen2.5-14B-Instruct\",  # Changed from Qwen2.5-14B-Instruct\n",
    ")\n",
    "\n",
    "# Initialize the server\n",
    "# Training and inference will run on Weights & Biases servers\n",
    "backend = ServerlessBackend()\n",
    "\n",
    "# Register the model with the Serverless Backend (sets up logging, inference, and training)\n",
    "await model.register(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9e83a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Rollout function defined!\n"
     ]
    }
   ],
   "source": [
    "from textwrap import dedent\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import AsyncOpenAI\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "import art\n",
    "\n",
    "MAX_TURNS = 4\n",
    "\n",
    "\n",
    "class FinalAnswer(BaseModel):\n",
    "    answer: str\n",
    "    source_ids: list[str]\n",
    "\n",
    "\n",
    "class LegalScenario(BaseModel):\n",
    "    id: str\n",
    "    question: str\n",
    "    gold_answer: str | None = None\n",
    "    gold_part_ids: list[str] | None = None\n",
    "\n",
    "\n",
    "class LegalScenarioStep(BaseModel):\n",
    "    step: int\n",
    "    scenario: LegalScenario\n",
    "\n",
    "\n",
    "async def rollout(model: art.Model, legal_scenario_step: LegalScenarioStep) -> art.Trajectory:\n",
    "    \"\"\"Execute one trajectory rollout\"\"\"\n",
    "    scenario = legal_scenario_step.scenario\n",
    "    \n",
    "    traj = art.Trajectory(\n",
    "        reward=0.0,\n",
    "        messages_and_choices=[],\n",
    "        metadata={\"scenario_id\": scenario.id, \"step\": legal_scenario_step.step},\n",
    "    )\n",
    "\n",
    "    # YOUR CUSTOM PROMPT HERE\n",
    "    system_prompt = dedent(\n",
    "        f\"\"\"\n",
    "        You are a legal research assistant that can search legal documents to answer questions.\n",
    "\n",
    "        You have access to the following tools:\n",
    "\n",
    "        - search_keyword(query: str, num: int) -> str: Search using keyword/BM25 search for exact term matches.\n",
    "        - search_semantic(query: str, num: int) -> str: Search using semantic/vector search for conceptual similarity.\n",
    "        - read_document_part(part_id: str) -> str: Read a document part by ID. Part IDs use hierarchical format (e.g., A:B:C). To access parent parts, remove the last segment (e.g., A:B:C â†’ parent is A:B).\n",
    "\n",
    "        You may call one tool per turn, for up to {MAX_TURNS} turns, before giving your final answer.\n",
    "\n",
    "        In each turn, you should analyze what information you need and respond with EITHER a tool call OR your final answer.\n",
    "\n",
    "        For tool calls, use this format:\n",
    "        <think>\n",
    "        [your reasoning for what to search for and why]\n",
    "        </think>\n",
    "        <tool>\n",
    "        {{\"name\": \"tool_name\", \"args\": {{\"query\": \"search query\"}}}}\n",
    "        </tool>\n",
    "\n",
    "        When you have enough information, give your final answer in this format:\n",
    "\n",
    "        <think>\n",
    "        [your reasoning for the answer]\n",
    "        </think>\n",
    "        <answer>\n",
    "        [your comprehensive answer citing the evidence you found or \"I don't know\" if you didn't get enough information]\n",
    "\n",
    "        <sources>\n",
    "        <source>doc_id_1</source>\n",
    "        </sources>\n",
    "        </answer>\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    traj.messages_and_choices = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": scenario.question},\n",
    "    ]\n",
    "\n",
    "    # Define tools\n",
    "    def search_keyword_tool(query: str, num: int = 5) -> str:\n",
    "        return keyword_search(query, num)\n",
    "\n",
    "    def search_semantic_tool(query: str, num: int = 5) -> str:\n",
    "        searcher = FAISSSemanticSearch()\n",
    "        return searcher.search(query, num)\n",
    "\n",
    "    def read_document_part_tool(part_id: str) -> str:\n",
    "        return read_document_part(part_id)\n",
    "\n",
    "    def return_final_answer(answer: str, source_ids: list[str]) -> FinalAnswer:\n",
    "        return FinalAnswer(answer=answer, source_ids=source_ids)\n",
    "\n",
    "    tools = [search_keyword_tool, search_semantic_tool, read_document_part_tool, return_final_answer]\n",
    "    tools_by_name = {t.__name__: t for t in tools}\n",
    "    traj.tools = [convert_to_openai_tool(t) for t in tools]\n",
    "\n",
    "    client = AsyncOpenAI(\n",
    "        base_url=model.inference_base_url,\n",
    "        api_key=model.inference_api_key,\n",
    "    )\n",
    "\n",
    "    for _ in range(MAX_TURNS):\n",
    "        response = await client.chat.completions.create(\n",
    "            model=model.get_inference_name(),\n",
    "            temperature=1,\n",
    "            messages=traj.messages(),\n",
    "            tools=traj.tools,\n",
    "        )\n",
    "\n",
    "        response_message = response.choices[0].message\n",
    "        traj.messages_and_choices.append(response.choices[0])\n",
    "\n",
    "        if not response_message.tool_calls:\n",
    "            return traj\n",
    "\n",
    "        try:\n",
    "            for tool_call in response_message.tool_calls:\n",
    "                tool_name = tool_call.function.name\n",
    "                if tool_name in tools_by_name:\n",
    "                    tool_args = json.loads(tool_call.function.arguments)\n",
    "                    result = tools_by_name[tool_name](**tool_args)\n",
    "                    traj.messages_and_choices.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"name\": tool_name,\n",
    "                        \"content\": str(result),\n",
    "                    })\n",
    "\n",
    "                    if tool_name == \"return_final_answer\":\n",
    "                        return traj\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return traj\n",
    "\n",
    "    return traj\n",
    "\n",
    "\n",
    "print(\"âœ… Rollout function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "055f5c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ./snippet_data.json...\n",
      "âœ… Loaded 100 scenarios\n",
      "\n",
      "ðŸ§ª Testing Gemini judge via OpenRouter...\n",
      "  Scores: [2.0, 0.0]\n",
      "\n",
      "Rank 1: Score 2.000\n",
      "  Response: The Marshall Court reasoned that a land grant from a state constitutes a binding...\n",
      "\n",
      "Rank 2: Score 0.000\n",
      "  Response: I don't know anything about this legal question....\n",
      "\n",
      "âœ… Gemini judge working!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from litellm import acompletion\n",
    "\n",
    "# Load your training data\n",
    "DATA_FILE = \"./snippet_data.json\"\n",
    "\n",
    "print(f\"Loading data from {DATA_FILE}...\")\n",
    "with open(DATA_FILE, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert to LegalScenario objects\n",
    "training_scenarios = []\n",
    "for item in data.get(\"items\", []):\n",
    "    for row in item.get(\"rows\", []):\n",
    "        sources = row.get(\"sources\", [])\n",
    "        gold_part_ids = sources if sources else []\n",
    "        \n",
    "        training_scenarios.append(\n",
    "            LegalScenario(\n",
    "                id=str(row[\"row_index\"]),\n",
    "                question=row[\"question\"],\n",
    "                gold_answer=row.get(\"model_answer\", \"\"),\n",
    "                gold_part_ids=gold_part_ids\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"âœ… Loaded {len(training_scenarios)} scenarios\")\n",
    "\n",
    "\n",
    "# Custom RULER function using OpenRouter\n",
    "async def gemini_ruler_score_group(group: art.TrajectoryGroup) -> art.TrajectoryGroup:\n",
    "    \"\"\"Score trajectories using Gemini 2.5 Flash via OpenRouter\"\"\"\n",
    "    \n",
    "    trajectories = group.trajectories\n",
    "    if len(trajectories) <= 1:\n",
    "        for traj in trajectories:\n",
    "            traj.reward = 0.0\n",
    "        return group\n",
    "    \n",
    "    # Extract responses\n",
    "    responses = []\n",
    "    for traj in trajectories:\n",
    "        messages = traj.messages()\n",
    "        if messages:\n",
    "            last_msg = messages[-1].get(\"content\", \"\")\n",
    "            responses.append(last_msg)\n",
    "        else:\n",
    "            responses.append(\"\")\n",
    "    \n",
    "    # Build comparison prompt\n",
    "    comparison_text = \"\\n\\n\".join([\n",
    "        f\"**Response {i+1}:**\\n{resp[:500]}\"  # Truncate for API limits\n",
    "        for i, resp in enumerate(responses)\n",
    "    ])\n",
    "    \n",
    "    judge_prompt = f\"\"\"Compare these {len(responses)} legal research responses and rank them.\n",
    "\n",
    "Criteria:\n",
    "1. Correctness and accuracy (most important)\n",
    "2. Proper citation of sources with part_ids\n",
    "3. Completeness of answer\n",
    "\n",
    "Responses:\n",
    "{comparison_text}\n",
    "\n",
    "Return ONLY a JSON array of scores from 0.0 to 2.0, one score per response in order.\n",
    "Higher scores = better responses.\n",
    "Example: [2.0, 0.5, 1.5]\n",
    "\n",
    "Your scores:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Call Gemini via OpenRouter (correct format)\n",
    "        response = await acompletion(\n",
    "        model=\"openrouter/google/gemini-2.5-flash\",  # openrouter/ prefix\n",
    "        messages=[{\"role\": \"user\", \"content\": judge_prompt}],\n",
    "        api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
    "        max_tokens=100,\n",
    "    )\n",
    "        \n",
    "        # Parse scores\n",
    "        result_text = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Extract JSON array\n",
    "        import re\n",
    "        json_match = re.search(r'\\[[\\d\\.,\\s]+\\]', result_text)\n",
    "        if json_match:\n",
    "            scores = json.loads(json_match.group())\n",
    "        else:\n",
    "            scores = json.loads(result_text)\n",
    "        \n",
    "        # Assign scores\n",
    "        for traj, score in zip(trajectories, scores):\n",
    "            traj.reward = float(score)\n",
    "        \n",
    "        print(f\"  Scores: {scores}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error in judge: {e}\")\n",
    "        # Fallback: random variation\n",
    "        import random\n",
    "        for traj in trajectories:\n",
    "            traj.reward = random.uniform(0.5, 1.5)\n",
    "    \n",
    "    return group\n",
    "\n",
    "\n",
    "# Test the judge\n",
    "print(\"\\nðŸ§ª Testing Gemini judge via OpenRouter...\")\n",
    "\n",
    "test_scenario = training_scenarios[0]\n",
    "base_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a legal research agent.\"},\n",
    "    {\"role\": \"user\", \"content\": test_scenario.question},\n",
    "]\n",
    "\n",
    "good_traj = art.Trajectory(\n",
    "    messages_and_choices=[\n",
    "        *base_messages,\n",
    "        {\"role\": \"assistant\", \"content\": test_scenario.gold_answer},\n",
    "    ],\n",
    "    reward=0,\n",
    ")\n",
    "\n",
    "bad_traj = art.Trajectory(\n",
    "    messages_and_choices=[\n",
    "        *base_messages,\n",
    "        {\"role\": \"assistant\", \"content\": \"I don't know anything about this legal question.\"},\n",
    "    ],\n",
    "    reward=0,\n",
    ")\n",
    "\n",
    "test_group = art.TrajectoryGroup(trajectories=[good_traj, bad_traj])\n",
    "\n",
    "# Score using custom function\n",
    "judged_group = await gemini_ruler_score_group(test_group)\n",
    "\n",
    "# Display results\n",
    "sorted_trajs = sorted(judged_group.trajectories, key=lambda t: t.reward, reverse=True)\n",
    "for rank, traj in enumerate(sorted_trajs, 1):\n",
    "    msgs = traj.messages()\n",
    "    print(f\"\\nRank {rank}: Score {traj.reward:.3f}\")\n",
    "    print(f\"  Response: {msgs[-1]['content'][:80]}...\")\n",
    "\n",
    "print(\"\\nâœ… Gemini judge working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e719f56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshng2025\u001b[0m (\u001b[33mImperial-College-London-SPQR\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/maindir/wandb/run-20251011_232628-utrrklto</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025/runs/utrrklto' target=\"_blank\">legal-rag-rl-training</a></strong> to <a href='https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025' target=\"_blank\">https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025/runs/utrrklto' target=\"_blank\">https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025/runs/utrrklto</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [litellm, openai] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Weave is installed but not imported. Add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting training loop...\n",
      "\n",
      "ðŸ’» Model inference running on: W&B Serverless (not your A100s)\n",
      "ðŸ“Š W&B Dashboard: https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025/runs/utrrklto\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating dataset:  19%|â–ˆâ–Š        | 28/150 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 28 | Epoch 0 | Epoch Step 28 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  6.03it/s, reward=0, completion_tokens=89.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.8, 1.0, 1.8, 1.0, 1.8, 1.0]\n",
      "  Scores: [1.0, 1.2, 1.8, 1.5, 1.3, 1.5]\n",
      "  Rewards: avg=1.392, max=1.800, min=1.000\n",
      "  Correct: 12, IDK: 0, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.65s/it, entropy=0.464, grad_norm=0.361, loss=0.0707, policy_loss=0.0707]\n",
      "Iterating dataset:  19%|â–ˆâ–‰        | 29/150 [00:25<51:29, 25.53s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Step 28 complete\n",
      "\n",
      "=== Step 29 | Epoch 0 | Epoch Step 29 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:03<00:00,  2.81it/s, exceptions=2, reward=0, completion_tokens=91.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.2, 1.4, 1.6, 0.8, 1.2, 1.6]\n",
      "  Scores: [1.0, 1.5, 2.0, 1.5]\n",
      "  Rewards: avg=1.380, max=2.000, min=0.800\n",
      "  Correct: 9, IDK: 1, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:16<00:00,  8.36s/it, entropy=0.585, grad_norm=0.857, loss=0.111, policy_loss=0.111]\n",
      "Iterating dataset:  20%|â–ˆâ–ˆ        | 30/150 [00:51<51:29, 25.74s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Step 29 complete\n",
      "\n",
      "=== Step 30 | Epoch 0 | Epoch Step 30 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:03<00:00,  2.76it/s, exceptions=2, reward=0, completion_tokens=97.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.5, 1.8, 1.8, 1.7]\n",
      "  Scores: [1.5, 1.5, 1.5, 1.7, 1.8, 0.5]\n",
      "  Rewards: avg=1.530, max=1.800, min=0.500\n",
      "  Correct: 9, IDK: 1, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 97\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# Train on judged trajectories\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m model.delete_checkpoints()\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m model.train(\n\u001b[32m     98\u001b[39m     judged_groups,\n\u001b[32m     99\u001b[39m     config=art.TrainConfig(learning_rate=training_config[\u001b[33m\"\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m\"\u001b[39m]),\n\u001b[32m    100\u001b[39m )\n\u001b[32m    102\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… Step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch.step\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m complete\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    104\u001b[39m step_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniforge3/lib/python3.12/site-packages/art/model.py:385\u001b[39m, in \u001b[36mTrainableModel.train\u001b[39m\u001b[34m(self, trajectory_groups, config, _config, verbose)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain\u001b[39m(\n\u001b[32m    370\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    371\u001b[39m     trajectory_groups: Iterable[TrajectoryGroup],\n\u001b[32m   (...)\u001b[39m\u001b[32m    374\u001b[39m     verbose: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    375\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    376\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[33;03m    Reinforce fine-tune the model with a batch of trajectory groups.\u001b[39;00m\n\u001b[32m    378\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    383\u001b[39m \u001b[33;03m            not yet part of the public API. Use at your own risk.\u001b[39;00m\n\u001b[32m    384\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.backend()._train_model(\n\u001b[32m    386\u001b[39m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(trajectory_groups), config, _config \u001b[38;5;129;01mor\u001b[39;00m {}, verbose\n\u001b[32m    387\u001b[39m     ):\n\u001b[32m    388\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniforge3/lib/python3.12/site-packages/art/serverless/backend.py:139\u001b[39m, in \u001b[36mServerlessBackend._train_model\u001b[39m\u001b[34m(self, model, trajectory_groups, config, dev_config, verbose)\u001b[39m\n\u001b[32m    137\u001b[39m pbar: tqdm.tqdm | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio.sleep(\u001b[32m0.5\u001b[39m)\n\u001b[32m    140\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.training_jobs.events.list(\n\u001b[32m    141\u001b[39m         training_job_id=training_job.id, after=after \u001b[38;5;129;01mor\u001b[39;00m NOT_GIVEN\n\u001b[32m    142\u001b[39m     ):\n\u001b[32m    143\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m event.type == \u001b[33m\"\u001b[39m\u001b[33mgradient_step\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniforge3/lib/python3.12/asyncio/tasks.py:665\u001b[39m, in \u001b[36msleep\u001b[39m\u001b[34m(delay, result)\u001b[39m\n\u001b[32m    661\u001b[39m h = loop.call_later(delay,\n\u001b[32m    662\u001b[39m                     futures._set_result_unless_cancelled,\n\u001b[32m    663\u001b[39m                     future, result)\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    667\u001b[39m     h.cancel()\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._post_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0x7f2249109c70>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f2249d84ef0, execution_count=7 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 7f224a0df740, raw_cell=\"from art.utils import iterate_dataset\n",
      "import wandb..\" transformed_cell=\"from art.utils import iterate_dataset\n",
      "import wandb..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22737368372e766173742e61692e31782e413130302e38306762227d/workspace/maindir/main%20%5Bserverless%5D.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "socket.send() raised exception.\n"
     ]
    }
   ],
   "source": [
    "from art.utils import iterate_dataset\n",
    "import wandb\n",
    "\n",
    "# Initialize W&B\n",
    "wandb.login(key=os.environ[\"WANDB_API_KEY\"])\n",
    "run = wandb.init(\n",
    "    project=\"IBM-Datathon-Z-2025\",\n",
    "    config={\n",
    "        \"model\": \"Qwen/Qwen2.5-14B-Instruct\",\n",
    "        \"groups_per_step\": 2,\n",
    "        \"num_epochs\": 3,\n",
    "        \"rollouts_per_group\": 6,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"max_steps\": 50,\n",
    "        \"max_turns\": MAX_TURNS,\n",
    "    },\n",
    "    name=\"legal-rag-rl-training\"\n",
    ")\n",
    "\n",
    "# Training config\n",
    "training_config = run.config\n",
    "\n",
    "# Create training iterator\n",
    "training_iterator = iterate_dataset(\n",
    "    training_scenarios,\n",
    "    groups_per_step=training_config[\"groups_per_step\"],\n",
    "    num_epochs=training_config[\"num_epochs\"],\n",
    "    initial_step=await model.get_step(),\n",
    ")\n",
    "\n",
    "print(\"ðŸš€ Starting training loop...\\n\")\n",
    "print(f\"ðŸ’» Model inference running on: W&B Serverless (not your A100s)\")\n",
    "print(f\"ðŸ“Š W&B Dashboard: {run.url}\\n\")\n",
    "\n",
    "step_count = 0\n",
    "\n",
    "for batch in training_iterator:\n",
    "    print(f\"=== Step {batch.step} | Epoch {batch.epoch} | Epoch Step {batch.epoch_step} ===\")\n",
    "    print(f\"Batch: {len(batch.items)} scenarios\")\n",
    "    \n",
    "    # Create trajectory groups\n",
    "    groups = []\n",
    "    for scenario in batch.items:\n",
    "        groups.append(\n",
    "            art.TrajectoryGroup(\n",
    "                (\n",
    "                    rollout(model, LegalScenarioStep(step=batch.step, scenario=scenario))\n",
    "                    for _ in range(training_config[\"rollouts_per_group\"])\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Gather trajectories\n",
    "    finished_groups = await art.gather_trajectory_groups(\n",
    "        groups,\n",
    "        pbar_desc=\"Gathering trajectories\",\n",
    "        max_exceptions=training_config[\"rollouts_per_group\"] * len(batch.items),\n",
    "    )\n",
    "    \n",
    "    # Judge with custom Gemini function\n",
    "    judged_groups = []\n",
    "    for group in finished_groups:\n",
    "        judged_group = await gemini_ruler_score_group(group)\n",
    "        judged_groups.append(judged_group)\n",
    "    \n",
    "    # Calculate metrics before training\n",
    "    all_rewards = [t.reward for g in judged_groups for t in g.trajectories]\n",
    "    avg_reward = sum(all_rewards) / len(all_rewards)\n",
    "    max_reward = max(all_rewards)\n",
    "    min_reward = min(all_rewards)\n",
    "    \n",
    "    # Count trajectories by reward band\n",
    "    correct_count = sum(1 for r in all_rewards if r >= 1.0)\n",
    "    idk_count = sum(1 for r in all_rewards if 0.0 <= r < 1.0)\n",
    "    wrong_count = sum(1 for r in all_rewards if -1.0 <= r < 0.0)\n",
    "    format_error_count = sum(1 for r in all_rewards if r < -1.0)\n",
    "    \n",
    "    # Log to W&B\n",
    "    wandb.log({\n",
    "        \"step\": batch.step,\n",
    "        \"epoch\": batch.epoch,\n",
    "        \"avg_reward\": avg_reward,\n",
    "        \"max_reward\": max_reward,\n",
    "        \"min_reward\": min_reward,\n",
    "        \"correct_count\": correct_count,\n",
    "        \"idk_count\": idk_count,\n",
    "        \"wrong_count\": wrong_count,\n",
    "        \"format_error_count\": format_error_count,\n",
    "        \"total_trajectories\": len(all_rewards),\n",
    "    })\n",
    "    \n",
    "    print(f\"  Rewards: avg={avg_reward:.3f}, max={max_reward:.3f}, min={min_reward:.3f}\")\n",
    "    print(f\"  Correct: {correct_count}, IDK: {idk_count}, Wrong: {wrong_count}, Format Errors: {format_error_count}\")\n",
    "    \n",
    "    # Train on judged trajectories\n",
    "    await model.delete_checkpoints()\n",
    "    await model.train(\n",
    "        judged_groups,\n",
    "        config=art.TrainConfig(learning_rate=training_config[\"learning_rate\"]),\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Step {batch.step} complete\\n\")\n",
    "    \n",
    "    step_count += 1\n",
    "    \n",
    "    # Stop after max_steps\n",
    "    if batch.step >= training_config[\"max_steps\"]:\n",
    "        break\n",
    "\n",
    "run.finish()\n",
    "print(\"ðŸŽ‰ Training complete!\")\n",
    "print(f\"ðŸ“Š View results: {run.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b06c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
