{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3873e61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-core\n",
      "  Using cached langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: tenacity in /opt/miniforge3/lib/python3.12/site-packages (9.1.2)\n",
      "Collecting datasets\n",
      "  Using cached datasets-4.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting vllm\n",
      "  Using cached vllm-0.11.0-cp38-abi3-manylinux1_x86_64.whl.metadata (17 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core)\n",
      "  Using cached langsmith-0.4.34-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/miniforge3/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /opt/miniforge3/lib/python3.12/site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /opt/miniforge3/lib/python3.12/site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/miniforge3/lib/python3.12/site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/miniforge3/lib/python3.12/site-packages (from langchain-core) (2.11.10)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/miniforge3/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/miniforge3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /opt/miniforge3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/miniforge3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/miniforge3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.4)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/miniforge3/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.23.0)\n",
      "Requirement already satisfied: anyio in /opt/miniforge3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.11.0)\n",
      "Requirement already satisfied: certifi in /opt/miniforge3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniforge3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/miniforge3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/miniforge3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniforge3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/miniforge3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/miniforge3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
      "Requirement already satisfied: filelock in /opt/miniforge3/lib/python3.12/site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniforge3/lib/python3.12/site-packages (from datasets) (2.3.3)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Using cached pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/miniforge3/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /opt/miniforge3/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /opt/miniforge3/lib/python3.12/site-packages (from datasets) (0.35.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/miniforge3/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/miniforge3/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: regex in /opt/miniforge3/lib/python3.12/site-packages (from vllm) (2025.9.18)\n",
      "Requirement already satisfied: cachetools in /opt/miniforge3/lib/python3.12/site-packages (from vllm) (6.2.0)\n",
      "Requirement already satisfied: psutil in /opt/miniforge3/lib/python3.12/site-packages (from vllm) (7.1.0)\n",
      "Collecting sentencepiece (from vllm)\n",
      "  Using cached sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting blake3 (from vllm)\n",
      "  Using cached blake3-1.0.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (217 bytes)\n",
      "Collecting py-cpuinfo (from vllm)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: transformers>=4.55.2 in /opt/miniforge3/lib/python3.12/site-packages (from vllm) (4.57.0)\n",
      "Requirement already satisfied: tokenizers>=0.21.1 in /opt/miniforge3/lib/python3.12/site-packages (from vllm) (0.22.1)\n",
      "Requirement already satisfied: protobuf in /opt/miniforge3/lib/python3.12/site-packages (from vllm) (6.32.1)\n",
      "Collecting fastapi>=0.115.0 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Using cached fastapi-0.119.0-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: openai>=1.99.1 in /opt/miniforge3/lib/python3.12/site-packages (from vllm) (1.99.1)\n",
      "Collecting prometheus_client>=0.18.0 (from vllm)\n",
      "  Using cached prometheus_client-0.23.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pillow in /opt/miniforge3/lib/python3.12/site-packages (from vllm) (11.3.0)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
      "  Using cached prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /opt/miniforge3/lib/python3.12/site-packages (from vllm) (0.12.0)\n",
      "Collecting lm-format-enforcer==0.11.3 (from vllm)\n",
      "  Using cached lm_format_enforcer-0.11.3-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting llguidance<0.8.0,>=0.7.11 (from vllm)\n",
      "  Using cached llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting outlines_core==0.2.11 (from vllm)\n",
      "  Using cached outlines_core-0.2.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: diskcache==5.6.3 in /opt/miniforge3/lib/python3.12/site-packages (from vllm) (5.6.3)\n",
      "Collecting lark==1.2.2 (from vllm)\n",
      "  Using cached lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting xgrammar==0.1.25 (from vllm)\n",
      "  Using cached xgrammar-0.1.25-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting partial-json-parser (from vllm)\n",
      "  Using cached partial_json_parser-0.2.1.1.post6-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in /opt/miniforge3/lib/python3.12/site-packages (from vllm) (27.1.0)\n",
      "Collecting msgspec (from vllm)\n",
      "  Using cached msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting gguf>=0.13.0 (from vllm)\n",
      "  Using cached gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting mistral_common>=1.8.2 (from mistral_common[audio,image]>=1.8.2->vllm)\n",
      "  Using cached mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting opencv-python-headless>=4.11.0 (from vllm)\n",
      "  Using cached opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: six>=1.16.0 in /opt/miniforge3/lib/python3.12/site-packages (from vllm) (1.17.0)\n",
      "Collecting setuptools<80,>=77.0.3 (from vllm)\n",
      "  Using cached setuptools-79.0.1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting einops (from vllm)\n",
      "  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting compressed-tensors==0.11.0 (from vllm)\n",
      "  Using cached compressed_tensors-0.11.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting depyf==0.19.0 (from vllm)\n",
      "  Using cached depyf-0.19.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting cloudpickle (from vllm)\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: watchfiles in /opt/miniforge3/lib/python3.12/site-packages (from vllm) (1.1.0)\n",
      "Collecting python-json-logger (from vllm)\n",
      "  Using cached python_json_logger-4.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting scipy (from vllm)\n",
      "  Using cached scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting ninja (from vllm)\n",
      "  Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pybase64 in /opt/miniforge3/lib/python3.12/site-packages (from vllm) (1.4.2)\n",
      "Collecting cbor2 (from vllm)\n",
      "  Using cached cbor2-5.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting setproctitle (from vllm)\n",
      "  Using cached setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (10 kB)\n",
      "Collecting openai-harmony>=0.0.3 (from vllm)\n",
      "  Using cached openai_harmony-0.0.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
      "Collecting numba==0.61.2 (from vllm)\n",
      "  Using cached numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting ray>=2.48.0 (from ray[cgraph]>=2.48.0->vllm)\n",
      "  Using cached ray-2.50.0-cp312-cp312-manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: torch==2.8.0 in /opt/miniforge3/lib/python3.12/site-packages (from vllm) (2.8.0)\n",
      "Collecting torchaudio==2.8.0 (from vllm)\n",
      "  Using cached torchaudio-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
      "Collecting torchvision==0.23.0 (from vllm)\n",
      "  Using cached torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting xformers==0.0.32.post1 (from vllm)\n",
      "  Using cached xformers-0.0.32.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: frozendict in /opt/miniforge3/lib/python3.12/site-packages (from compressed-tensors==0.11.0->vllm) (2.4.6)\n",
      "Collecting astor (from depyf==0.19.0->vllm)\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.11.3->vllm)\n",
      "  Using cached interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm)\n",
      "  Using cached llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting numpy>=1.17 (from datasets)\n",
      "  Using cached numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/miniforge3/lib/python3.12/site-packages (from torch==2.8.0->vllm) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/miniforge3/lib/python3.12/site-packages (from torch==2.8.0->vllm) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/miniforge3/lib/python3.12/site-packages (from torch==2.8.0->vllm) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/miniforge3/lib/python3.12/site-packages (from torch==2.8.0->vllm) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/miniforge3/lib/python3.12/site-packages (from torch==2.8.0->vllm) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/miniforge3/lib/python3.12/site-packages (from torch==2.8.0->vllm) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/miniforge3/lib/python3.12/site-packages (from torch==2.8.0->vllm) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/miniforge3/lib/python3.12/site-packages (from torch==2.8.0->vllm) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/miniforge3/lib/python3.12/site-packages (from torch==2.8.0->vllm) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/miniforge3/lib/python3.12/site-packages (from torch==2.8.0->vllm) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/miniforge3/lib/python3.12/site-packages (from torch==2.8.0->vllm) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/miniforge3/lib/python3.12/site-packages (from torch==2.8.0->vllm) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/miniforge3/lib/python3.12/site-packages (from torch==2.8.0->vllm) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/miniforge3/lib/python3.12/site-packages (from torch==2.8.0->vllm) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/miniforge3/lib/python3.12/site-packages (from torch==2.8.0->vllm) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/miniforge3/lib/python3.12/site-packages (from torch==2.8.0->vllm) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/miniforge3/lib/python3.12/site-packages (from torch==2.8.0->vllm) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/miniforge3/lib/python3.12/site-packages (from torch==2.8.0->vllm) (3.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/miniforge3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/miniforge3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniforge3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniforge3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniforge3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/miniforge3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/miniforge3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Collecting starlette<0.49.0,>=0.40.0 (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm)\n",
      "  Using cached starlette-0.48.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/miniforge3/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.3.1)\n",
      "Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Using cached fastapi_cli-0.0.13-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Using cached email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: uvicorn>=0.12.0 in /opt/miniforge3/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.37.0)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n",
      "  Using cached dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typer>=0.15.1 in /opt/miniforge3/lib/python3.12/site-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.19.2)\n",
      "Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Using cached rich_toolkit-0.15.1-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Using cached fastapi_cloud_cli-0.3.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Using cached rignore-0.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: sentry-sdk>=2.20.0 in /opt/miniforge3/lib/python3.12/site-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.41.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniforge3/lib/python3.12/site-packages (from jinja2->torch==2.8.0->vllm) (3.0.3)\n",
      "Requirement already satisfied: jsonschema>=4.21.1 in /opt/miniforge3/lib/python3.12/site-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (4.25.1)\n",
      "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n",
      "  Using cached pydantic_extra_types-2.10.6-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/miniforge3/lib/python3.12/site-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/miniforge3/lib/python3.12/site-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/miniforge3/lib/python3.12/site-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.27.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/miniforge3/lib/python3.12/site-packages (from openai>=1.99.1->vllm) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/miniforge3/lib/python3.12/site-packages (from openai>=1.99.1->vllm) (0.11.0)\n",
      "Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n",
      "  Using cached pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting click!=8.3.0,>=7.0 (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm)\n",
      "  Using cached msgpack-1.1.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting cupy-cuda12x (from ray[cgraph]>=2.48.0->vllm)\n",
      "  Using cached cupy_cuda12x-13.6.0-cp312-cp312-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniforge3/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniforge3/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.3.0)\n",
      "Requirement already satisfied: rich>=13.7.1 in /opt/miniforge3/lib/python3.12/site-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (14.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/miniforge3/lib/python3.12/site-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/miniforge3/lib/python3.12/site-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/miniforge3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniforge3/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.8.0->vllm) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/miniforge3/lib/python3.12/site-packages (from transformers>=4.55.2->vllm) (0.6.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/miniforge3/lib/python3.12/site-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /opt/miniforge3/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/miniforge3/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.1.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /opt/miniforge3/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/miniforge3/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
      "Collecting fastrlock>=0.5 (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm)\n",
      "  Using cached fastrlock-0.8.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting soundfile>=0.12.1 (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/miniforge3/lib/python3.12/site-packages (from soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /opt/miniforge3/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.22)\n",
      "Collecting soxr>=0.5.0 (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n",
      "  Downloading soxr-1.0.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniforge3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading langchain_core-0.3.79-py3-none-any.whl (449 kB)\n",
      "Downloading langsmith-0.4.34-py3-none-any.whl (386 kB)\n",
      "Downloading datasets-4.2.0-py3-none-any.whl (506 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading vllm-0.11.0-cp38-abi3-manylinux1_x86_64.whl (438.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.2/438.2 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading compressed_tensors-0.11.0-py3-none-any.whl (179 kB)\n",
      "Downloading depyf-0.19.0-py3-none-any.whl (39 kB)\n",
      "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Downloading lm_format_enforcer-0.11.3-py3-none-any.whl (45 kB)\n",
      "Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m128.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading outlines_core-0.2.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m130.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.32.post1-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m124.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xgrammar-0.1.25-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m150.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m124.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-79.0.1-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m144.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.119.0-py3-none-any.whl (107 kB)\n",
      "Downloading starlette-0.48.0-py3-none-any.whl (73 kB)\n",
      "Downloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
      "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
      "Downloading fastapi_cli-0.0.13-py3-none-any.whl (11 kB)\n",
      "Downloading fastapi_cloud_cli-0.3.1-py3-none-any.whl (19 kB)\n",
      "Downloading gguf-0.17.1-py3-none-any.whl (96 kB)\n",
      "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Downloading mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m154.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai_harmony-0.0.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading prometheus_client-0.23.1-py3-none-any.whl (61 kB)\n",
      "Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
      "Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m129.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_extra_types-2.10.6-py3-none-any.whl (40 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m125.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ray-2.50.0-cp312-cp312-manylinux2014_x86_64.whl (71.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.1.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (427 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading rich_toolkit-0.15.1-py3-none-any.whl (29 kB)\n",
      "Downloading rignore-0.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (951 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m951.1/951.1 kB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading blake3-1.0.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (387 kB)\n",
      "Downloading cbor2-5.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (284 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading cupy_cuda12x-13.6.0-cp312-cp312-manylinux2014_x86_64.whl (112.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.9/112.9 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastrlock-0.8.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (53 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m128.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-1.0.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (238 kB)\n",
      "Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
      "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl (10 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading python_json_logger-4.0.0-py3-none-any.whl (15 kB)\n",
      "Downloading scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m140.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m136.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (32 kB)\n",
      "Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Installing collected packages: pytz, py-cpuinfo, fastrlock, xxhash, tzdata, setuptools, setproctitle, sentencepiece, rignore, python-multipart, python-json-logger, pycountry, pyarrow, prometheus_client, partial-json-parser, outlines_core, numpy, ninja, msgspec, msgpack, llvmlite, llguidance, lark, interegular, einops, dnspython, dill, cloudpickle, click, cbor2, blake3, astor, starlette, soxr, soundfile, scipy, pandas, opencv-python-headless, numba, multiprocess, gguf, email-validator, depyf, cupy-cuda12x, rich-toolkit, pydantic-extra-types, prometheus-fastapi-instrumentator, openai-harmony, lm-format-enforcer, langsmith, fastapi, xformers, torchvision, torchaudio, ray, langchain-core, fastapi-cloud-cli, fastapi-cli, datasets, xgrammar, mistral_common, compressed-tensors, vllm\n",
      "\u001b[2K  Attempting uninstall: setuptools━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/63\u001b[0m [tzdata]\n",
      "\u001b[2K    Found existing installation: setuptools 80.9.0━━━━━━━━━━━━\u001b[0m \u001b[32m 4/63\u001b[0m [tzdata]\n",
      "\u001b[2K    Uninstalling setuptools-80.9.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/63\u001b[0m [tzdata]\n",
      "\u001b[2K      Successfully uninstalled setuptools-80.9.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/63\u001b[0m [setuptools]\n",
      "\u001b[2K  Attempting uninstall: numpym\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/63\u001b[0m [prometheus_client]\n",
      "\u001b[2K    Found existing installation: numpy 2.3.3━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/63\u001b[0m [prometheus_client]\n",
      "\u001b[2K    Uninstalling numpy-2.3.3:0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/63\u001b[0m [prometheus_client]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.3━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/63\u001b[0m [prometheus_client]\n",
      "\u001b[2K  Attempting uninstall: click[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/63\u001b[0m [dill]thon]]nt]\n",
      "\u001b[2K    Found existing installation: click 8.3.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/63\u001b[0m [dill]\n",
      "\u001b[2K    Uninstalling click-8.3.0:╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/63\u001b[0m [dill]\n",
      "\u001b[2K      Successfully uninstalled click-8.3.0━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/63\u001b[0m [dill]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63/63\u001b[0m [vllm]0m [vllm]0m [mistral_common]li]less]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "polyfile-weave 0.5.7 requires setuptools>=80.9.0, but you have setuptools 79.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed astor-0.8.1 blake3-1.0.7 cbor2-5.7.0 click-8.2.1 cloudpickle-3.1.1 compressed-tensors-0.11.0 cupy-cuda12x-13.6.0 datasets-4.2.0 depyf-0.19.0 dill-0.4.0 dnspython-2.8.0 einops-0.8.1 email-validator-2.3.0 fastapi-0.119.0 fastapi-cli-0.0.13 fastapi-cloud-cli-0.3.1 fastrlock-0.8.3 gguf-0.17.1 interegular-0.3.3 langchain-core-0.3.79 langsmith-0.4.34 lark-1.2.2 llguidance-0.7.30 llvmlite-0.44.0 lm-format-enforcer-0.11.3 mistral_common-1.8.5 msgpack-1.1.2 msgspec-0.19.0 multiprocess-0.70.16 ninja-1.13.0 numba-0.61.2 numpy-2.2.6 openai-harmony-0.0.4 opencv-python-headless-4.12.0.88 outlines_core-0.2.11 pandas-2.3.3 partial-json-parser-0.2.1.1.post6 prometheus-fastapi-instrumentator-7.1.0 prometheus_client-0.23.1 py-cpuinfo-9.0.0 pyarrow-21.0.0 pycountry-24.6.1 pydantic-extra-types-2.10.6 python-json-logger-4.0.0 python-multipart-0.0.20 pytz-2025.2 ray-2.50.0 rich-toolkit-0.15.1 rignore-0.7.0 scipy-1.16.2 sentencepiece-0.2.1 setproctitle-1.3.7 setuptools-79.0.1 soundfile-0.13.1 soxr-1.0.0 starlette-0.48.0 torchaudio-2.8.0 torchvision-0.23.0 tzdata-2025.2 vllm-0.11.0 xformers-0.0.32.post1 xgrammar-0.1.25 xxhash-3.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install openpipe-art==0.5.0 langchain-core tenacity datasets vllm faiss-cpu chromadb requests lxml numpy transformers torch gql==3.4.1 peft \n",
    "!pip install langchain-core tenacity datasets vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "965eaa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from secretsConfig import oaiKey, wandbKey, openRouterKey  # Add openRouterKey\n",
    "\n",
    "# Required for RULER judge model\n",
    "os.environ[\"OPENAI_API_KEY\"] = oaiKey\n",
    "\n",
    "# Required for Weights & Biases\n",
    "os.environ[\"WANDB_API_KEY\"] = wandbKey\n",
    "\n",
    "# Required for OpenRouter (Gemini judge)\n",
    "os.environ[\"OPENROUTER_API_KEY\"] = openRouterKey  # ADD THIS LINE\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"OPENAI_API_KEY is required for RULER functionality.\")\n",
    "\n",
    "if not os.environ.get(\"WANDB_API_KEY\"):\n",
    "    raise ValueError(\"WANDB_API_KEY is required for W&B.\")\n",
    "\n",
    "if not os.environ.get(\"OPENROUTER_API_KEY\"):\n",
    "    raise ValueError(\"OPENROUTER_API_KEY is required for Gemini judge.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6c3f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IBM_Z_Datathon_RAG.semantic_search import FAISSSemanticSearch\n",
    "from IBM_Z_Datathon_RAG.KeywordSearch import keyword_search\n",
    "from IBM_Z_Datathon_RAG.ReadDocumentPart import read_document_part\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "535e659f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import random\n",
    "\n",
    "import art\n",
    "from art.serverless.backend import ServerlessBackend\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Declare the model - CHANGED TO QWEN3-14B\n",
    "model = art.TrainableModel(\n",
    "    name=\"legal-agent-001\",\n",
    "    project=\"legal-rag\",\n",
    "    base_model=\"Qwen/Qwen2.5-14B-Instruct\",  # Changed from Qwen2.5-14B-Instruct\n",
    ")\n",
    "\n",
    "# Initialize the server\n",
    "# Training and inference will run on Weights & Biases servers\n",
    "backend = ServerlessBackend()\n",
    "\n",
    "# Register the model with the Serverless Backend (sets up logging, inference, and training)\n",
    "await model.register(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9e83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import AsyncOpenAI\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "import art\n",
    "\n",
    "MAX_TURNS = 4\n",
    "\n",
    "\n",
    "class FinalAnswer(BaseModel):\n",
    "    answer: str\n",
    "    source_ids: list[str]\n",
    "\n",
    "\n",
    "class LegalScenario(BaseModel):\n",
    "    id: str\n",
    "    question: str\n",
    "    gold_answer: str | None = None\n",
    "    gold_part_ids: list[str] | None = None\n",
    "\n",
    "\n",
    "class LegalScenarioStep(BaseModel):\n",
    "    step: int\n",
    "    scenario: LegalScenario\n",
    "\n",
    "\n",
    "async def rollout(model: art.Model, legal_scenario_step: LegalScenarioStep) -> art.Trajectory:\n",
    "    \"\"\"Execute one trajectory rollout\"\"\"\n",
    "    scenario = legal_scenario_step.scenario\n",
    "    \n",
    "    traj = art.Trajectory(\n",
    "        reward=0.0,\n",
    "        messages_and_choices=[],\n",
    "        metadata={\"scenario_id\": scenario.id, \"step\": legal_scenario_step.step},\n",
    "    )\n",
    "\n",
    "    # YOUR CUSTOM PROMPT HERE\n",
    "    system_prompt = dedent(\n",
    "        f\"\"\"\n",
    "        You are a legal research assistant that can search legal documents to answer questions.\n",
    "\n",
    "        You have access to the following tools:\n",
    "\n",
    "        - search_keyword(query: str, num: int) -> str: Search using keyword/BM25 search for exact term matches.\n",
    "        - search_semantic(query: str, num: int) -> str: Search using semantic/vector search for conceptual similarity.\n",
    "        - read_document_part(part_id: str) -> str: Read a document part by ID. Part IDs use hierarchical format (e.g., A:B:C). To access parent parts, remove the last segment (e.g., A:B:C → parent is A:B).\n",
    "\n",
    "        You may call one tool per turn, for up to {MAX_TURNS} turns, before giving your final answer.\n",
    "\n",
    "        In each turn, you should analyze what information you need and respond with EITHER a tool call OR your final answer.\n",
    "\n",
    "        For tool calls, use this format:\n",
    "        <think>\n",
    "        [your reasoning for what to search for and why]\n",
    "        </think>\n",
    "        <tool>\n",
    "        {{\"name\": \"tool_name\", \"args\": {{\"query\": \"search query\"}}}}\n",
    "        </tool>\n",
    "\n",
    "        When you have enough information, give your final answer in this format:\n",
    "\n",
    "        <think>\n",
    "        [your reasoning for the answer]\n",
    "        </think>\n",
    "        <answer>\n",
    "        [your comprehensive answer citing the evidence you found or \"I don't know\" if you didn't get enough information]\n",
    "\n",
    "        <sources>\n",
    "        <source>doc_id_1</source>\n",
    "        </sources>\n",
    "        </answer>\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    traj.messages_and_choices = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": scenario.question},\n",
    "    ]\n",
    "\n",
    "    # Define tools\n",
    "    def search_keyword_tool(query: str, num: int = 5) -> str:\n",
    "        return keyword_search(query, num)\n",
    "\n",
    "    def search_semantic_tool(query: str, num: int = 5) -> str:\n",
    "        searcher = FAISSSemanticSearch()\n",
    "        return searcher.search(query, num)\n",
    "\n",
    "    def read_document_part_tool(part_id: str) -> str:\n",
    "        return read_document_part(part_id)\n",
    "\n",
    "    def return_final_answer(answer: str, source_ids: list[str]) -> FinalAnswer:\n",
    "        return FinalAnswer(answer=answer, source_ids=source_ids)\n",
    "\n",
    "    tools = [search_keyword_tool, search_semantic_tool, read_document_part_tool, return_final_answer]\n",
    "    tools_by_name = {t.__name__: t for t in tools}\n",
    "    traj.tools = [convert_to_openai_tool(t) for t in tools]\n",
    "\n",
    "    client = AsyncOpenAI(\n",
    "        base_url=model.inference_base_url,\n",
    "        api_key=model.inference_api_key,\n",
    "    )\n",
    "\n",
    "    for _ in range(MAX_TURNS):\n",
    "        response = await client.chat.completions.create(\n",
    "            model=model.get_inference_name(),\n",
    "            temperature=1,\n",
    "            messages=traj.messages(),\n",
    "            tools=traj.tools,\n",
    "        )\n",
    "\n",
    "        response_message = response.choices[0].message\n",
    "        traj.messages_and_choices.append(response.choices[0])\n",
    "\n",
    "        if not response_message.tool_calls:\n",
    "            return traj\n",
    "\n",
    "        try:\n",
    "            for tool_call in response_message.tool_calls:\n",
    "                tool_name = tool_call.function.name\n",
    "                if tool_name in tools_by_name:\n",
    "                    tool_args = json.loads(tool_call.function.arguments)\n",
    "                    result = tools_by_name[tool_name](**tool_args)\n",
    "                    traj.messages_and_choices.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"name\": tool_name,\n",
    "                        \"content\": str(result),\n",
    "                    })\n",
    "\n",
    "                    if tool_name == \"return_final_answer\":\n",
    "                        return traj\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return traj\n",
    "\n",
    "    return traj\n",
    "\n",
    "\n",
    "print(\"✅ Rollout function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "055f5c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ./snippet_data.json...\n",
      "✅ Loaded 100 scenarios\n",
      "\n",
      "🧪 Testing Gemini judge via OpenRouter...\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "  Error in judge: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=google/gemini-2.0-flash-exp:free\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n",
      "\n",
      "Rank 1: Score 1.139\n",
      "  Response: The Marshall Court reasoned that a land grant from a state constitutes a binding...\n",
      "\n",
      "Rank 2: Score 0.525\n",
      "  Response: I don't know anything about this legal question....\n",
      "\n",
      "✅ Gemini judge working!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from litellm import acompletion\n",
    "\n",
    "# Load your training data\n",
    "DATA_FILE = \"./snippet_data.json\"\n",
    "\n",
    "print(f\"Loading data from {DATA_FILE}...\")\n",
    "with open(DATA_FILE, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert to LegalScenario objects\n",
    "training_scenarios = []\n",
    "for item in data.get(\"items\", []):\n",
    "    for row in item.get(\"rows\", []):\n",
    "        sources = row.get(\"sources\", [])\n",
    "        gold_part_ids = sources if sources else []\n",
    "        \n",
    "        training_scenarios.append(\n",
    "            LegalScenario(\n",
    "                id=str(row[\"row_index\"]),\n",
    "                question=row[\"question\"],\n",
    "                gold_answer=row.get(\"model_answer\", \"\"),\n",
    "                gold_part_ids=gold_part_ids\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"✅ Loaded {len(training_scenarios)} scenarios\")\n",
    "\n",
    "\n",
    "# Custom RULER function using OpenRouter\n",
    "async def gemini_ruler_score_group(group: art.TrajectoryGroup) -> art.TrajectoryGroup:\n",
    "    \"\"\"Score trajectories using Gemini 2.5 Flash via OpenRouter\"\"\"\n",
    "    \n",
    "    trajectories = group.trajectories\n",
    "    if len(trajectories) <= 1:\n",
    "        for traj in trajectories:\n",
    "            traj.reward = 0.0\n",
    "        return group\n",
    "    \n",
    "    # Extract responses\n",
    "    responses = []\n",
    "    for traj in trajectories:\n",
    "        messages = traj.messages()\n",
    "        if messages:\n",
    "            last_msg = messages[-1].get(\"content\", \"\")\n",
    "            responses.append(last_msg)\n",
    "        else:\n",
    "            responses.append(\"\")\n",
    "    \n",
    "    # Build comparison prompt\n",
    "    comparison_text = \"\\n\\n\".join([\n",
    "        f\"**Response {i+1}:**\\n{resp[:500]}\"  # Truncate for API limits\n",
    "        for i, resp in enumerate(responses)\n",
    "    ])\n",
    "    \n",
    "    judge_prompt = f\"\"\"Compare these {len(responses)} legal research responses and rank them.\n",
    "\n",
    "Criteria:\n",
    "1. Correctness and accuracy (most important)\n",
    "2. Proper citation of sources with part_ids\n",
    "3. Completeness of answer\n",
    "\n",
    "Responses:\n",
    "{comparison_text}\n",
    "\n",
    "Return ONLY a JSON array of scores from 0.0 to 2.0, one score per response in order.\n",
    "Higher scores = better responses.\n",
    "Example: [2.0, 0.5, 1.5]\n",
    "\n",
    "Your scores:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Call Gemini via OpenRouter\n",
    "        response = await acompletion(\n",
    "            model=\"google/gemini-2.0-flash-exp:free\",  # Free tier\n",
    "            messages=[{\"role\": \"user\", \"content\": judge_prompt}],\n",
    "            api_base=\"https://openrouter.ai/api/v1\",\n",
    "            api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
    "            max_tokens=100,\n",
    "        )\n",
    "        \n",
    "        # Parse scores\n",
    "        result_text = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Extract JSON array\n",
    "        import re\n",
    "        json_match = re.search(r'\\[[\\d\\.,\\s]+\\]', result_text)\n",
    "        if json_match:\n",
    "            scores = json.loads(json_match.group())\n",
    "        else:\n",
    "            scores = json.loads(result_text)\n",
    "        \n",
    "        # Assign scores\n",
    "        for traj, score in zip(trajectories, scores):\n",
    "            traj.reward = float(score)\n",
    "        \n",
    "        print(f\"  Scores: {scores}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error in judge: {e}\")\n",
    "        # Fallback: random variation\n",
    "        import random\n",
    "        for traj in trajectories:\n",
    "            traj.reward = random.uniform(0.5, 1.5)\n",
    "    \n",
    "    return group\n",
    "\n",
    "\n",
    "# Test the judge\n",
    "print(\"\\n🧪 Testing Gemini judge via OpenRouter...\")\n",
    "\n",
    "test_scenario = training_scenarios[0]\n",
    "base_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a legal research agent.\"},\n",
    "    {\"role\": \"user\", \"content\": test_scenario.question},\n",
    "]\n",
    "\n",
    "good_traj = art.Trajectory(\n",
    "    messages_and_choices=[\n",
    "        *base_messages,\n",
    "        {\"role\": \"assistant\", \"content\": test_scenario.gold_answer},\n",
    "    ],\n",
    "    reward=0,\n",
    ")\n",
    "\n",
    "bad_traj = art.Trajectory(\n",
    "    messages_and_choices=[\n",
    "        *base_messages,\n",
    "        {\"role\": \"assistant\", \"content\": \"I don't know anything about this legal question.\"},\n",
    "    ],\n",
    "    reward=0,\n",
    ")\n",
    "\n",
    "test_group = art.TrajectoryGroup(trajectories=[good_traj, bad_traj])\n",
    "\n",
    "# Score using custom function\n",
    "judged_group = await gemini_ruler_score_group(test_group)\n",
    "\n",
    "# Display results\n",
    "sorted_trajs = sorted(judged_group.trajectories, key=lambda t: t.reward, reverse=True)\n",
    "for rank, traj in enumerate(sorted_trajs, 1):\n",
    "    msgs = traj.messages()\n",
    "    print(f\"\\nRank {rank}: Score {traj.reward:.3f}\")\n",
    "    print(f\"  Response: {msgs[-1]['content'][:80]}...\")\n",
    "\n",
    "print(\"\\n✅ Gemini judge working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e719f56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting training loop...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating dataset:   0%|          | 0/150 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 0 | Epoch 0 | Epoch Step 0 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed to parse XML: [Errno 2] No such file or directory: 'Plessy v. Ferguson separate but equal doctrine Justice Harlan dissent'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from art.utils import iterate_dataset\n",
    "\n",
    "# Training config\n",
    "training_config = {\n",
    "    \"groups_per_step\": 2,\n",
    "    \"num_epochs\": 3,\n",
    "    \"rollouts_per_group\": 6,\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"max_steps\": 50,\n",
    "}\n",
    "\n",
    "# Create training iterator\n",
    "training_iterator = iterate_dataset(\n",
    "    training_scenarios,\n",
    "    groups_per_step=training_config[\"groups_per_step\"],\n",
    "    num_epochs=training_config[\"num_epochs\"],\n",
    "    initial_step=await model.get_step(),\n",
    ")\n",
    "\n",
    "print(\"🚀 Starting training loop...\\n\")\n",
    "\n",
    "for batch in training_iterator:\n",
    "    print(f\"=== Step {batch.step} | Epoch {batch.epoch} | Epoch Step {batch.epoch_step} ===\")\n",
    "    print(f\"Batch: {len(batch.items)} scenarios\")\n",
    "    \n",
    "    # Create trajectory groups\n",
    "    groups = []\n",
    "    for scenario in batch.items:\n",
    "        groups.append(\n",
    "            art.TrajectoryGroup(\n",
    "                (\n",
    "                    rollout(model, LegalScenarioStep(step=batch.step, scenario=scenario))\n",
    "                    for _ in range(training_config[\"rollouts_per_group\"])\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Gather trajectories\n",
    "    finished_groups = await art.gather_trajectory_groups(\n",
    "        groups,\n",
    "        pbar_desc=\"Gathering trajectories\",\n",
    "        max_exceptions=training_config[\"rollouts_per_group\"] * len(batch.items),\n",
    "    )\n",
    "    \n",
    "    # Judge with RULER (Gemini 2.5 Flash)\n",
    "    judged_groups = []\n",
    "    for group in finished_groups:\n",
    "        judged_group = await ruler_score_group(\n",
    "            group,\n",
    "            \"google/gemini-2.5-flash\",\n",
    "            debug=True\n",
    "        )\n",
    "        judged_groups.append(judged_group)\n",
    "    \n",
    "    # Train on judged trajectories\n",
    "    await model.delete_checkpoints()\n",
    "    await model.train(\n",
    "        judged_groups,\n",
    "        config=art.TrainConfig(learning_rate=training_config[\"learning_rate\"]),\n",
    "    )\n",
    "    \n",
    "    # Calculate metrics\n",
    "    all_rewards = [t.reward for g in judged_groups for t in g.trajectories]\n",
    "    avg_reward = sum(all_rewards) / len(all_rewards)\n",
    "    \n",
    "    print(f\"✅ Step {batch.step} complete | Avg Reward: {avg_reward:.3f}\\n\")\n",
    "    \n",
    "    # Stop after max_steps\n",
    "    if batch.step >= training_config[\"max_steps\"]:\n",
    "        break\n",
    "\n",
    "print(\"🎉 Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b06c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
