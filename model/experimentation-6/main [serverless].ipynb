{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3873e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpipe-art==0.5.0 langchain-core tenacity datasets vllm faiss-cpu chromadb requests lxml numpy transformers torch gql==3.4.1 peft \n",
    "# !pip install langchain-core tenacity datasets vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965eaa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from secretsConfig import oaiKey, wandbKey, openRouterKey  # Add openRouterKey\n",
    "\n",
    "# Required for RULER judge model\n",
    "os.environ[\"OPENAI_API_KEY\"] = oaiKey\n",
    "\n",
    "# Required for Weights & Biases\n",
    "os.environ[\"WANDB_API_KEY\"] = wandbKey\n",
    "\n",
    "# Required for OpenRouter (Gemini judge)\n",
    "os.environ[\"OPENROUTER_API_KEY\"] = openRouterKey  # ADD THIS LINE\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"OPENAI_API_KEY is required for RULER functionality.\")\n",
    "\n",
    "if not os.environ.get(\"WANDB_API_KEY\"):\n",
    "    raise ValueError(\"WANDB_API_KEY is required for W&B.\")\n",
    "\n",
    "if not os.environ.get(\"OPENROUTER_API_KEY\"):\n",
    "    raise ValueError(\"OPENROUTER_API_KEY is required for Gemini judge.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6c3f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tools wrapped with error handling and validation\n"
     ]
    }
   ],
   "source": [
    "from IBM_Z_Datathon_RAG.semantic_search import FAISSSemanticSearch\n",
    "from IBM_Z_Datathon_RAG.KeywordSearch import keyword_search\n",
    "from IBM_Z_Datathon_RAG.ReadDocumentPart import read_document_part\n",
    "\n",
    "# Wrap tools with error handling that tracks mistakes\n",
    "class ToolError:\n",
    "    \"\"\"Marker for tool execution errors\"\"\"\n",
    "    def __init__(self, message: str):\n",
    "        self.message = message\n",
    "\n",
    "_original_keyword_search = keyword_search\n",
    "_original_read_document_part = read_document_part\n",
    "\n",
    "def keyword_search(query: str, num: int = 5) -> str:\n",
    "    \"\"\"Safe keyword search wrapper\"\"\"\n",
    "    try:\n",
    "        return _original_keyword_search(query, num)\n",
    "    except Exception as e:\n",
    "        error_msg = f\"[TOOL ERROR] keyword_search failed: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "\n",
    "def read_document_part(part_id: str) -> str:\n",
    "    \"\"\"Safe read_document_part wrapper - validates part_id format\"\"\"\n",
    "    try:\n",
    "        # Validate part_id format (should be like \"doc:section:pX\", not a search query)\n",
    "        if \" \" in part_id or len(part_id) > 100:\n",
    "            error_msg = f\"[INVALID PART_ID] '{part_id[:50]}...' is not a valid part_id format. Part IDs should be like 'doc:section:pX'. Use search tools first to find valid part IDs.\"\n",
    "            print(f\"[ERROR] Model tried to read invalid part_id: {part_id[:50]}...\")\n",
    "            return error_msg\n",
    "        \n",
    "        return _original_read_document_part(part_id)\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        error_msg = f\"[PART NOT FOUND] Part ID '{part_id}' does not exist. Use search_keyword or search_semantic first to find valid part IDs.\"\n",
    "        print(f\"[ERROR] {error_msg}\")\n",
    "        return error_msg\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"[TOOL ERROR] Failed to read document part: {str(e)}\"\n",
    "        print(f\"[ERROR] {error_msg}\")\n",
    "        return error_msg\n",
    "\n",
    "print(\"‚úÖ Tools wrapped with error handling and validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "535e659f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import random\n",
    "\n",
    "import art\n",
    "from art.serverless.backend import ServerlessBackend\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Declare the model - CHANGED TO QWEN3-14B\n",
    "model = art.TrainableModel(\n",
    "    name=\"legal-agent-001\",\n",
    "    project=\"legal-rag\",\n",
    "    base_model=\"Qwen/Qwen2.5-14B-Instruct\",  # Changed from Qwen2.5-14B-Instruct\n",
    ")\n",
    "\n",
    "# Initialize the server\n",
    "# Training and inference will run on Weights & Biases servers\n",
    "backend = ServerlessBackend()\n",
    "\n",
    "# Register the model with the Serverless Backend (sets up logging, inference, and training)\n",
    "await model.register(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9e83a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Rollout function defined!\n"
     ]
    }
   ],
   "source": [
    "from textwrap import dedent\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import AsyncOpenAI\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "import art\n",
    "\n",
    "MAX_TURNS = 4\n",
    "\n",
    "\n",
    "class FinalAnswer(BaseModel):\n",
    "    answer: str\n",
    "    source_ids: list[str]\n",
    "\n",
    "\n",
    "class LegalScenario(BaseModel):\n",
    "    id: str\n",
    "    question: str\n",
    "    gold_answer: str | None = None\n",
    "    gold_part_ids: list[str] | None = None\n",
    "\n",
    "\n",
    "class LegalScenarioStep(BaseModel):\n",
    "    step: int\n",
    "    scenario: LegalScenario\n",
    "\n",
    "\n",
    "async def rollout(model: art.Model, legal_scenario_step: LegalScenarioStep) -> art.Trajectory:\n",
    "    \"\"\"Execute one trajectory rollout\"\"\"\n",
    "    scenario = legal_scenario_step.scenario\n",
    "    \n",
    "    traj = art.Trajectory(\n",
    "        reward=0.0,\n",
    "        messages_and_choices=[],\n",
    "        metadata={\"scenario_id\": scenario.id, \"step\": legal_scenario_step.step},\n",
    "    )\n",
    "\n",
    "    # YOUR CUSTOM PROMPT HERE\n",
    "    system_prompt = dedent(\n",
    "        f\"\"\"\n",
    "        You are a legal research assistant that can search legal documents to answer questions.\n",
    "\n",
    "        You have access to the following tools:\n",
    "\n",
    "        - search_keyword(query: str, num: int) -> str: Search using keyword/BM25 search for exact term matches.\n",
    "        - search_semantic(query: str, num: int) -> str: Search using semantic/vector search for conceptual similarity.\n",
    "        - read_document_part(part_id: str) -> str: Read a document part by ID. Part IDs use hierarchical format (e.g., A:B:C). To access parent parts, remove the last segment (e.g., A:B:C ‚Üí parent is A:B).\n",
    "\n",
    "        You may call one tool per turn, for up to {MAX_TURNS} turns, before giving your final answer.\n",
    "\n",
    "        In each turn, you should analyze what information you need and respond with EITHER a tool call OR your final answer.\n",
    "\n",
    "        For tool calls, use this format:\n",
    "        <think>\n",
    "        [your reasoning for what to search for and why]\n",
    "        </think>\n",
    "        <tool>\n",
    "        {{\"name\": \"tool_name\", \"args\": {{\"query\": \"search query\"}}}}\n",
    "        </tool>\n",
    "\n",
    "        When you have enough information, give your final answer in this format:\n",
    "\n",
    "        <think>\n",
    "        [your reasoning for the answer]\n",
    "        </think>\n",
    "        <answer>\n",
    "        [your comprehensive answer citing the evidence you found or \"I don't know\" if you didn't get enough information]\n",
    "\n",
    "        <sources>\n",
    "        <source>doc_id_1</source>\n",
    "        </sources>\n",
    "        </answer>\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    traj.messages_and_choices = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": scenario.question},\n",
    "    ]\n",
    "\n",
    "    # Define tools\n",
    "    def search_keyword_tool(query: str, num: int = 5) -> str:\n",
    "        return keyword_search(query, num)\n",
    "\n",
    "    def search_semantic_tool(query: str, num: int = 5) -> str:\n",
    "        searcher = FAISSSemanticSearch()\n",
    "        return searcher.search(query, num)\n",
    "\n",
    "    def read_document_part_tool(part_id: str) -> str:\n",
    "        return read_document_part(part_id)\n",
    "\n",
    "    def return_final_answer(answer: str, source_ids: list[str]) -> FinalAnswer:\n",
    "        return FinalAnswer(answer=answer, source_ids=source_ids)\n",
    "\n",
    "    tools = [search_keyword_tool, search_semantic_tool, read_document_part_tool, return_final_answer]\n",
    "    tools_by_name = {t.__name__: t for t in tools}\n",
    "    traj.tools = [convert_to_openai_tool(t) for t in tools]\n",
    "\n",
    "    client = AsyncOpenAI(\n",
    "        base_url=model.inference_base_url,\n",
    "        api_key=model.inference_api_key,\n",
    "    )\n",
    "\n",
    "    for _ in range(MAX_TURNS):\n",
    "        response = await client.chat.completions.create(\n",
    "            model=model.get_inference_name(),\n",
    "            temperature=1,\n",
    "            messages=traj.messages(),\n",
    "            tools=traj.tools,\n",
    "        )\n",
    "\n",
    "        response_message = response.choices[0].message\n",
    "        traj.messages_and_choices.append(response.choices[0])\n",
    "\n",
    "        if not response_message.tool_calls:\n",
    "            return traj\n",
    "\n",
    "        try:\n",
    "            for tool_call in response_message.tool_calls:\n",
    "                tool_name = tool_call.function.name\n",
    "                if tool_name in tools_by_name:\n",
    "                    tool_args = json.loads(tool_call.function.arguments)\n",
    "                    result = tools_by_name[tool_name](**tool_args)\n",
    "                    traj.messages_and_choices.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"name\": tool_name,\n",
    "                        \"content\": str(result),\n",
    "                    })\n",
    "\n",
    "                    if tool_name == \"return_final_answer\":\n",
    "                        return traj\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return traj\n",
    "\n",
    "    return traj\n",
    "\n",
    "\n",
    "print(\"‚úÖ Rollout function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "055f5c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ./snippet_data.json...\n",
      "‚úÖ Loaded 100 scenarios\n",
      "\n",
      "üß™ Testing Gemini judge via OpenRouter...\n",
      "  ‚ö†Ô∏è  Trajectory penalized: -1.0 (no answer provided)\n",
      "  ‚ö†Ô∏è  Trajectory penalized: -1.0 (no answer provided)\n",
      "\n",
      "Rank 1: Score -1.000\n",
      "  Response: The Marshall Court reasoned that a land grant from a state constitutes a binding...\n",
      "\n",
      "Rank 2: Score -1.000\n",
      "  Response: I don't know anything about this legal question....\n",
      "\n",
      "‚úÖ Gemini judge working!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from litellm import acompletion\n",
    "\n",
    "# Load your training data\n",
    "DATA_FILE = \"./snippet_data.json\"\n",
    "\n",
    "print(f\"Loading data from {DATA_FILE}...\")\n",
    "with open(DATA_FILE, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert to LegalScenario objects\n",
    "training_scenarios = []\n",
    "for item in data.get(\"items\", []):\n",
    "    for row in item.get(\"rows\", []):\n",
    "        sources = row.get(\"sources\", [])\n",
    "        gold_part_ids = sources if sources else []\n",
    "        \n",
    "        training_scenarios.append(\n",
    "            LegalScenario(\n",
    "                id=str(row[\"row_index\"]),\n",
    "                question=row[\"question\"],\n",
    "                gold_answer=row.get(\"model_answer\", \"\"),\n",
    "                gold_part_ids=gold_part_ids\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(training_scenarios)} scenarios\")\n",
    "\n",
    "\n",
    "# Custom RULER function using OpenRouter\n",
    "async def gemini_ruler_score_group(group: art.TrajectoryGroup) -> art.TrajectoryGroup:\n",
    "    \"\"\"Score trajectories using Gemini 2.5 Flash via OpenRouter\"\"\"\n",
    "    \n",
    "    trajectories = group.trajectories\n",
    "    if len(trajectories) <= 1:\n",
    "        for traj in trajectories:\n",
    "            traj.reward = 0.0\n",
    "        return group\n",
    "    \n",
    "    # Check for tool errors and assign harsh penalties immediately\n",
    "    for traj in trajectories:\n",
    "        messages = traj.messages()\n",
    "        full_conversation = \"\\n\".join([str(m.get(\"content\", \"\")) for m in messages])\n",
    "        \n",
    "        # Harsh penalty for invalid tool usage\n",
    "        if \"[INVALID PART_ID]\" in full_conversation or \"[TOOL ERROR]\" in full_conversation:\n",
    "            traj.reward = -2.0  # Format/usage error band\n",
    "            print(f\"  ‚ö†Ô∏è  Trajectory penalized: -2.0 (invalid tool usage)\")\n",
    "            continue\n",
    "        \n",
    "        # Also check if no answer was provided\n",
    "        if not any(\"<answer>\" in str(m.get(\"content\", \"\")) for m in messages):\n",
    "            traj.reward = -1.0  # Wrong answer band\n",
    "            print(f\"  ‚ö†Ô∏è  Trajectory penalized: -1.0 (no answer provided)\")\n",
    "            continue\n",
    "    \n",
    "    # For trajectories without errors, use Gemini to compare\n",
    "    valid_trajectories = [t for t in trajectories if t.reward == 0.0]\n",
    "    \n",
    "    if len(valid_trajectories) <= 1:\n",
    "        return group\n",
    "    \n",
    "    # Extract responses from valid trajectories\n",
    "    responses = []\n",
    "    for traj in valid_trajectories:\n",
    "        messages = traj.messages()\n",
    "        if messages:\n",
    "            last_msg = messages[-1].get(\"content\", \"\")\n",
    "            responses.append(last_msg[:500])\n",
    "        else:\n",
    "            responses.append(\"\")\n",
    "    \n",
    "    # Build comparison prompt\n",
    "    comparison_text = \"\\n\\n\".join([\n",
    "        f\"**Response {i+1}:**\\n{resp}\"\n",
    "        for i, resp in enumerate(responses)\n",
    "    ])\n",
    "    \n",
    "    judge_prompt = f\"\"\"Compare these {len(responses)} legal research responses and rank them.\n",
    "\n",
    "Criteria:\n",
    "1. Correctness and accuracy (most important)\n",
    "2. Proper citation of sources with part_ids\n",
    "3. Completeness of answer\n",
    "\n",
    "Responses:\n",
    "{comparison_text}\n",
    "\n",
    "Return ONLY a JSON array of scores from 0.0 to 2.0, one score per response in order.\n",
    "Higher scores = better responses.\n",
    "Example: [2.0, 0.5, 1.5]\n",
    "\n",
    "Your scores:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Call Gemini via OpenRouter\n",
    "        response = await acompletion(\n",
    "            model=\"openrouter/google/gemini-2.5-flash\",\n",
    "            messages=[{\"role\": \"user\", \"content\": judge_prompt}],\n",
    "            api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
    "            max_tokens=100,\n",
    "        )\n",
    "        \n",
    "        # Parse scores\n",
    "        result_text = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Extract JSON array\n",
    "        import re\n",
    "        json_match = re.search(r'\\[[\\d\\.,\\s]+\\]', result_text)\n",
    "        if json_match:\n",
    "            scores = json.loads(json_match.group())\n",
    "        else:\n",
    "            scores = json.loads(result_text)\n",
    "        \n",
    "        # Assign scores to valid trajectories\n",
    "        for traj, score in zip(valid_trajectories, scores):\n",
    "            traj.reward = float(score)\n",
    "        \n",
    "        print(f\"  Scores: {scores}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error in judge: {e}\")\n",
    "        # Fallback: random variation for valid trajectories only\n",
    "        import random\n",
    "        for traj in valid_trajectories:\n",
    "            traj.reward = random.uniform(0.5, 1.5)\n",
    "    \n",
    "    return group\n",
    "\n",
    "\n",
    "# Test the judge\n",
    "print(\"\\nüß™ Testing Gemini judge via OpenRouter...\")\n",
    "\n",
    "test_scenario = training_scenarios[0]\n",
    "base_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a legal research agent.\"},\n",
    "    {\"role\": \"user\", \"content\": test_scenario.question},\n",
    "]\n",
    "\n",
    "good_traj = art.Trajectory(\n",
    "    messages_and_choices=[\n",
    "        *base_messages,\n",
    "        {\"role\": \"assistant\", \"content\": test_scenario.gold_answer},\n",
    "    ],\n",
    "    reward=0,\n",
    ")\n",
    "\n",
    "bad_traj = art.Trajectory(\n",
    "    messages_and_choices=[\n",
    "        *base_messages,\n",
    "        {\"role\": \"assistant\", \"content\": \"I don't know anything about this legal question.\"},\n",
    "    ],\n",
    "    reward=0,\n",
    ")\n",
    "\n",
    "test_group = art.TrajectoryGroup(trajectories=[good_traj, bad_traj])\n",
    "\n",
    "# Score using custom function\n",
    "judged_group = await gemini_ruler_score_group(test_group)\n",
    "\n",
    "# Display results\n",
    "sorted_trajs = sorted(judged_group.trajectories, key=lambda t: t.reward, reverse=True)\n",
    "for rank, traj in enumerate(sorted_trajs, 1):\n",
    "    msgs = traj.messages()\n",
    "    print(f\"\\nRank {rank}: Score {traj.reward:.3f}\")\n",
    "    print(f\"  Response: {msgs[-1]['content'][:80]}...\")\n",
    "\n",
    "print(\"\\n‚úÖ Gemini judge working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e719f56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshng2025\u001b[0m (\u001b[33mImperial-College-London-SPQR\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/maindir/wandb/run-20251011_233917-pmt5yxjw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025/runs/pmt5yxjw' target=\"_blank\">dashing-firebrand-6</a></strong> to <a href='https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025' target=\"_blank\">https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025/runs/pmt5yxjw' target=\"_blank\">https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025/runs/pmt5yxjw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [litellm, openai] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Weave is installed but not imported. Add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting training loop...\n",
      "\n",
      "üíª Model inference running on: W&B Serverless (not your A100s)\n",
      "üìä W&B Dashboard: https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025/runs/pmt5yxjw\n",
      "üè∑Ô∏è  Run name: dashing-firebrand-6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating dataset:   0%|          | 0/150 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 0 | Epoch 0 | Epoch Step 0 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:01<00:00,  6.23it/s, reward=0, completion_tokens=76.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.5, 1.0, 1.5, 1.0, 1.5, 1.5]\n",
      "  Scores: [0.5, 0.5, 0.5, 1.0, 1.5, 0.5]\n",
      "  Rewards: avg=1.042, max=1.500, min=0.500\n",
      "  Correct: 8, IDK: 4, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.12s/it, entropy=0.284, grad_norm=0.397, loss=0.64, policy_loss=0.64]\n",
      "Iterating dataset:   1%|          | 1/150 [00:23<59:26, 23.93s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 0 complete\n",
      "\n",
      "=== Step 1 | Epoch 0 | Epoch Step 1 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.68it/s, exceptions=2, reward=0, completion_tokens=89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.5, 0.5, 1.0, 1.0, 2.0]\n",
      "  Scores: [1.0, 1.5, 1.0, 2.0, 1.5]\n",
      "  Rewards: avg=1.300, max=2.000, min=0.500\n",
      "  Correct: 9, IDK: 1, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.37s/it, entropy=0.292, grad_norm=0.444, loss=0.272, policy_loss=0.272]\n",
      "Iterating dataset:   1%|‚ñè         | 2/150 [00:50<1:03:31, 25.75s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 1 complete\n",
      "\n",
      "=== Step 2 | Epoch 0 | Epoch Step 2 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:04<00:00,  2.42it/s, exceptions=2, reward=0, completion_tokens=89.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.0, 1.5, 0.5, 2.0, 1.0]\n",
      "  Scores: [1.8, 1.0, 1.9, 1.8, 1.7]\n",
      "  Rewards: avg=1.420, max=2.000, min=0.500\n",
      "  Correct: 9, IDK: 1, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:15<00:00,  7.72s/it, entropy=0.511, grad_norm=0.35, loss=-0.606, policy_loss=-0.606]\n",
      "Iterating dataset:   2%|‚ñè         | 3/150 [01:15<1:02:11, 25.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 2 complete\n",
      "\n",
      "=== Step 3 | Epoch 0 | Epoch Step 3 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.93it/s, exceptions=2, reward=0, completion_tokens=85.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.5, 1.5, 1.5, 2.0]\n",
      "  Scores: [1.0, 1.0, 1.2, 1.2, 1.2, 1.8]\n",
      "  Rewards: avg=1.390, max=2.000, min=1.000\n",
      "  Correct: 10, IDK: 0, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.34s/it, entropy=0.384, grad_norm=0.294, loss=0.0259, policy_loss=0.0259]\n",
      "Iterating dataset:   3%|‚ñé         | 4/150 [01:41<1:02:05, 25.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 3 complete\n",
      "\n",
      "=== Step 4 | Epoch 0 | Epoch Step 4 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.66it/s, exceptions=2, reward=0, completion_tokens=93.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.8, 1.2, 1.7, 1.3, 1.5]\n",
      "  Scores: [1.5, 1.8, 1.8, 1.5, 1.9]\n",
      "  Rewards: avg=1.600, max=1.900, min=1.200\n",
      "  Correct: 10, IDK: 0, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.34s/it, entropy=0.375, grad_norm=0.688, loss=0.747, policy_loss=0.747]\n",
      "Iterating dataset:   3%|‚ñé         | 5/150 [02:07<1:01:56, 25.63s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 4 complete\n",
      "\n",
      "=== Step 5 | Epoch 0 | Epoch Step 5 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.85it/s, exceptions=2, reward=0, completion_tokens=97.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.0, 1.0, 1.0, 1.5, 1.0]\n",
      "  Scores: [1.5, 0.5, 0.5, 1.5, 0.0]\n",
      "  Rewards: avg=0.950, max=1.500, min=0.000\n",
      "  Correct: 7, IDK: 3, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:15<00:00,  7.73s/it, entropy=0.535, grad_norm=0.293, loss=-0.283, policy_loss=-0.283]\n",
      "Iterating dataset:   4%|‚ñç         | 6/150 [02:31<1:00:28, 25.20s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 5 complete\n",
      "\n",
      "=== Step 6 | Epoch 0 | Epoch Step 6 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:04<00:00,  2.39it/s, exceptions=2, reward=0, completion_tokens=95.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.0, 1.0, 1.0, 1.0]\n",
      "  Scores: [1.5, 1.7, 0.5, 1.7, 1.7, 0.8]\n",
      "  Rewards: avg=1.190, max=1.700, min=0.500\n",
      "  Correct: 8, IDK: 2, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.04s/it, entropy=0.192, grad_norm=0.191, loss=0.177, policy_loss=0.177]\n",
      "Iterating dataset:   5%|‚ñç         | 7/150 [02:57<1:00:41, 25.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 6 complete\n",
      "\n",
      "=== Step 7 | Epoch 0 | Epoch Step 7 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 11/12 [00:03<00:00,  3.08it/s, exceptions=1, reward=0, completion_tokens=88.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.6, 1.8, 1.7, 1.9, 1.7]\n",
      "  Scores: [1.7, 1.8, 1.0, 1.5, 1.9, 1.6]\n",
      "  Rewards: avg=1.655, max=1.900, min=1.000\n",
      "  Correct: 11, IDK: 0, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.07s/it, entropy=0.264, grad_norm=0.638, loss=0.444, policy_loss=0.444]\n",
      "Iterating dataset:   5%|‚ñå         | 8/150 [03:22<1:00:01, 25.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 7 complete\n",
      "\n",
      "=== Step 8 | Epoch 0 | Epoch Step 8 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.67it/s, exceptions=2, reward=0, completion_tokens=94.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.0, 1.0, 1.0, 1.0]\n",
      "  Scores: [1.8, 1.0, 1.7, 0.8, 1.9, 2.0]\n",
      "  Rewards: avg=1.320, max=2.000, min=0.800\n",
      "  Correct: 9, IDK: 1, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.03s/it, entropy=0.449, grad_norm=0.466, loss=-0.673, policy_loss=-0.674]\n",
      "Iterating dataset:   6%|‚ñå         | 9/150 [03:48<59:47, 25.45s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 8 complete\n",
      "\n",
      "=== Step 9 | Epoch 0 | Epoch Step 9 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.72it/s, exceptions=2, reward=0, completion_tokens=95.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.8, 1.9, 1.8, 1.7, 1.5]\n",
      "  Scores: [1.6, 1.8, 1.5, 1.7, 1.9]\n",
      "  Rewards: avg=1.720, max=1.900, min=1.500\n",
      "  Correct: 10, IDK: 0, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.02s/it, entropy=0.334, grad_norm=0.277, loss=0.0094, policy_loss=0.00945]\n",
      "Iterating dataset:   7%|‚ñã         | 10/150 [04:13<59:14, 25.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 9 complete\n",
      "\n",
      "=== Step 10 | Epoch 0 | Epoch Step 10 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.69it/s, exceptions=2, reward=0, completion_tokens=71.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [0.5, 0.5, 1.5, 1.5]\n",
      "  Scores: [1.0, 1.0, 1.0, 1.5, 0.0, 0.0]\n",
      "  Rewards: avg=0.850, max=1.500, min=0.000\n",
      "  Correct: 6, IDK: 4, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:15<00:00,  7.73s/it, entropy=0.264, grad_norm=0.878, loss=0.926, policy_loss=0.926]\n",
      "Iterating dataset:   7%|‚ñã         | 11/150 [04:38<58:23, 25.21s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 10 complete\n",
      "\n",
      "=== Step 11 | Epoch 0 | Epoch Step 11 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 11/12 [00:03<00:00,  3.45it/s, exceptions=1, reward=0, completion_tokens=64.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [0.5, 1.0, 0.5, 1.0, 1.5, 1.5]\n",
      "  Scores: [1.3, 1.8, 1.0, 1.9, 1.7]\n",
      "  Rewards: avg=1.245, max=1.900, min=0.500\n",
      "  Correct: 9, IDK: 2, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:16<00:00, 16.07s/it, entropy=0.318, grad_norm=0.435, loss=0.0427, policy_loss=0.0427]\n",
      "Iterating dataset:   8%|‚ñä         | 12/150 [05:03<57:48, 25.13s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 11 complete\n",
      "\n",
      "=== Step 12 | Epoch 0 | Epoch Step 12 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 11/12 [00:03<00:00,  3.19it/s, exceptions=1, reward=0, completion_tokens=78.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [0.5, 0.5, 1.0, 1.0, 2.0]\n",
      "  Scores: [1.5, 1.5, 1.7, 1.6, 1.8, 1.0]\n",
      "  Rewards: avg=1.282, max=2.000, min=0.500\n",
      "  Correct: 9, IDK: 2, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.34s/it, entropy=0.366, grad_norm=0.921, loss=0.986, policy_loss=0.986]\n",
      "Iterating dataset:   9%|‚ñä         | 13/150 [05:29<57:48, 25.32s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 12 complete\n",
      "\n",
      "=== Step 13 | Epoch 0 | Epoch Step 13 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.96it/s, exceptions=2, reward=0, completion_tokens=68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.5, 1.0, 1.0, 1.0, 1.0]\n",
      "  Scores: [1.5, 1.5, 1.0, 1.5, 1.5]\n",
      "  Rewards: avg=1.250, max=1.500, min=1.000\n",
      "  Correct: 10, IDK: 0, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:14<00:00, 14.84s/it, entropy=0.351, grad_norm=0.416, loss=0.0435, policy_loss=0.0435]\n",
      "Iterating dataset:   9%|‚ñâ         | 14/150 [05:53<56:29, 24.92s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 13 complete\n",
      "\n",
      "=== Step 14 | Epoch 0 | Epoch Step 14 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.66it/s, exceptions=2, reward=0, completion_tokens=81.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.5, 1.7, 1.0, 1.0, 2.0]\n",
      "  Scores: [0.5, 1.0, 1.0, 1.5, 1.7]\n",
      "  Rewards: avg=1.290, max=2.000, min=0.500\n",
      "  Correct: 9, IDK: 1, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.36s/it, entropy=0.36, grad_norm=3.39, loss=0.586, policy_loss=0.586]\n",
      "Iterating dataset:  10%|‚ñà         | 15/150 [06:19<57:08, 25.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 14 complete\n",
      "\n",
      "=== Step 15 | Epoch 0 | Epoch Step 15 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.78it/s, exceptions=2, reward=0, completion_tokens=88.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.0, 1.5, 1.0, 1.0, 2.0]\n",
      "  Scores: [1.8, 1.9, 1.7, 2.0, 1.6]\n",
      "  Rewards: avg=1.550, max=2.000, min=1.000\n",
      "  Correct: 10, IDK: 0, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:15<00:00,  7.75s/it, entropy=0.449, grad_norm=3.69, loss=-0.261, policy_loss=-0.261]\n",
      "Iterating dataset:  11%|‚ñà         | 16/150 [06:44<56:28, 25.28s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 15 complete\n",
      "\n",
      "=== Step 16 | Epoch 0 | Epoch Step 16 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.65it/s, exceptions=2, reward=0, completion_tokens=91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.0, 1.5, 1.5, 1.0, 1.5]\n",
      "  Scores: [2.0, 1.5, 1.0, 1.5, 1.5]\n",
      "  Rewards: avg=1.400, max=2.000, min=1.000\n",
      "  Correct: 10, IDK: 0, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.04s/it, entropy=0.499, grad_norm=0.953, loss=0.0712, policy_loss=0.0712]\n",
      "Iterating dataset:  11%|‚ñà‚ñè        | 17/150 [07:12<57:35, 25.98s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 16 complete\n",
      "\n",
      "=== Step 17 | Epoch 0 | Epoch Step 17 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.75it/s, exceptions=2, reward=0, completion_tokens=91.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.0, 1.5, 1.0, 1.0, 1.0]\n",
      "  Scores: [1.5, 0.5, 1.5, 1.0, 1.0]\n",
      "  Rewards: avg=1.100, max=1.500, min=0.500\n",
      "  Correct: 9, IDK: 1, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.04s/it, entropy=0.429, grad_norm=0.922, loss=0.937, policy_loss=0.937]\n",
      "Iterating dataset:  12%|‚ñà‚ñè        | 18/150 [07:37<56:25, 25.65s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 17 complete\n",
      "\n",
      "=== Step 18 | Epoch 0 | Epoch Step 18 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.81it/s, exceptions=2, reward=0, completion_tokens=81.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.4, 1.4, 1.4, 1.6, 1.4, 1.8]\n",
      "  Scores: [1.2, 1.8, 1.0, 1.5]\n",
      "  Rewards: avg=1.450, max=1.800, min=1.000\n",
      "  Correct: 10, IDK: 0, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.35s/it, entropy=0.343, grad_norm=0.55, loss=0.42, policy_loss=0.42]\n",
      "Iterating dataset:  13%|‚ñà‚ñé        | 19/150 [08:03<56:19, 25.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 18 complete\n",
      "\n",
      "=== Step 19 | Epoch 0 | Epoch Step 19 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.89it/s, exceptions=2, reward=0, completion_tokens=80.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.5, 1.0, 2.0, 1.0]\n",
      "  Scores: [1.0, 1.5, 1.0, 1.5, 2.0, 1.0]\n",
      "  Rewards: avg=1.350, max=2.000, min=1.000\n",
      "  Correct: 10, IDK: 0, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.05s/it, entropy=0.397, grad_norm=0.668, loss=0.322, policy_loss=0.322]\n",
      "Iterating dataset:  13%|‚ñà‚ñé        | 20/150 [08:28<55:26, 25.59s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 19 complete\n",
      "\n",
      "=== Step 20 | Epoch 0 | Epoch Step 20 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.89it/s, exceptions=2, reward=0, completion_tokens=88.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error in judge: Expecting value: line 1 column 1 (char 0)\n",
      "  Scores: [1.8, 1.2, 0.8, 1.5, 1.7]\n",
      "  Rewards: avg=1.160, max=1.800, min=0.675\n",
      "  Correct: 5, IDK: 5, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.35s/it, entropy=0.443, grad_norm=0.526, loss=-0.544, policy_loss=-0.544]\n",
      "Iterating dataset:  14%|‚ñà‚ñç        | 21/150 [08:54<55:27, 25.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 20 complete\n",
      "\n",
      "=== Step 21 | Epoch 0 | Epoch Step 21 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.75it/s, exceptions=2, reward=0, completion_tokens=49.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [0.5, 0.5, 1.0, 0.5, 1.5, 1.0]\n",
      "  Scores: [0.5, 0.5, 0.5, 1.5]\n",
      "  Rewards: avg=0.800, max=1.500, min=0.500\n",
      "  Correct: 4, IDK: 6, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:15<00:00, 15.46s/it, entropy=0.215, grad_norm=0.299, loss=0.0723, policy_loss=0.0723]\n",
      "Iterating dataset:  15%|‚ñà‚ñç        | 22/150 [09:19<54:17, 25.45s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 21 complete\n",
      "\n",
      "=== Step 22 | Epoch 0 | Epoch Step 22 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.82it/s, exceptions=2, reward=0, completion_tokens=93.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.5, 1.5, 1.8, 1.9, 1.0, 1.0]\n",
      "  Scores: [1.1, 1.2, 1.4, 1.8]\n",
      "  Rewards: avg=1.420, max=1.900, min=1.000\n",
      "  Correct: 10, IDK: 0, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.33s/it, entropy=0.427, grad_norm=1.5, loss=0.263, policy_loss=0.263]\n",
      "Iterating dataset:  15%|‚ñà‚ñå        | 23/150 [09:45<54:03, 25.54s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 22 complete\n",
      "\n",
      "=== Step 23 | Epoch 0 | Epoch Step 23 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.93it/s, exceptions=2, reward=0, completion_tokens=79.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.5, 1.0, 0.5, 0.5, 0.5, 1.0]\n",
      "  Scores: [1.7, 1.8, 1.9, 2.0]\n",
      "  Rewards: avg=1.240, max=2.000, min=0.500\n",
      "  Correct: 7, IDK: 3, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.04s/it, entropy=0.314, grad_norm=0.961, loss=-1.15, policy_loss=-1.15]\n",
      "Iterating dataset:  16%|‚ñà‚ñå        | 24/150 [10:10<53:15, 25.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 23 complete\n",
      "\n",
      "=== Step 24 | Epoch 0 | Epoch Step 24 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.66it/s, exceptions=2, reward=0, completion_tokens=93.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.5, 1.8, 1.8, 1.9, 1.9]\n",
      "  Scores: [1.8, 0.5, 1.5, 1.5, 1.8]\n",
      "  Rewards: avg=1.600, max=1.900, min=0.500\n",
      "  Correct: 9, IDK: 1, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from art.utils import iterate_dataset\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize W&B with auto-generated run name\n",
    "wandb.login(key=os.environ[\"WANDB_API_KEY\"])\n",
    "run = wandb.init(\n",
    "    project=\"IBM-Datathon-Z-2025\",\n",
    "    config={\n",
    "        \"model\": \"Qwen/Qwen2.5-14B-Instruct\",\n",
    "        \"groups_per_step\": 2,\n",
    "        \"num_epochs\": 3,\n",
    "        \"rollouts_per_group\": 6,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"max_steps\": 50,\n",
    "        \"max_turns\": MAX_TURNS,\n",
    "    },\n",
    "    # Remove the name parameter to get auto-generated names with numbers\n",
    "    # name=\"legal-rag-rl-training\"  # REMOVED THIS LINE\n",
    ")\n",
    "\n",
    "# Training config\n",
    "training_config = run.config\n",
    "\n",
    "# Create training iterator starting from step 0 (fresh run)\n",
    "training_iterator = iterate_dataset(\n",
    "    training_scenarios,\n",
    "    groups_per_step=training_config[\"groups_per_step\"],\n",
    "    num_epochs=training_config[\"num_epochs\"],\n",
    "    initial_step=0,  # CHANGED: Always start from 0 for fresh runs\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting training loop...\\n\")\n",
    "print(f\"üíª Model inference running on: W&B Serverless (not your A100s)\")\n",
    "print(f\"üìä W&B Dashboard: {run.url}\")\n",
    "print(f\"üè∑Ô∏è  Run name: {run.name}\\n\")\n",
    "\n",
    "step_count = 0\n",
    "\n",
    "for batch in training_iterator:\n",
    "    print(f\"=== Step {batch.step} | Epoch {batch.epoch} | Epoch Step {batch.epoch_step} ===\")\n",
    "    print(f\"Batch: {len(batch.items)} scenarios\")\n",
    "    \n",
    "    # Create trajectory groups\n",
    "    groups = []\n",
    "    for scenario in batch.items:\n",
    "        groups.append(\n",
    "            art.TrajectoryGroup(\n",
    "                (\n",
    "                    rollout(model, LegalScenarioStep(step=batch.step, scenario=scenario))\n",
    "                    for _ in range(training_config[\"rollouts_per_group\"])\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Gather trajectories\n",
    "    finished_groups = await art.gather_trajectory_groups(\n",
    "        groups,\n",
    "        pbar_desc=\"Gathering trajectories\",\n",
    "        max_exceptions=training_config[\"rollouts_per_group\"] * len(batch.items),\n",
    "    )\n",
    "    \n",
    "    # Judge with custom Gemini function\n",
    "    judged_groups = []\n",
    "    for group in finished_groups:\n",
    "        judged_group = await gemini_ruler_score_group(group)\n",
    "        judged_groups.append(judged_group)\n",
    "    \n",
    "    # Calculate metrics before training\n",
    "    all_rewards = [t.reward for g in judged_groups for t in g.trajectories]\n",
    "    avg_reward = sum(all_rewards) / len(all_rewards)\n",
    "    max_reward = max(all_rewards)\n",
    "    min_reward = min(all_rewards)\n",
    "    \n",
    "    # Count trajectories by reward band\n",
    "    correct_count = sum(1 for r in all_rewards if r >= 1.0)\n",
    "    idk_count = sum(1 for r in all_rewards if 0.0 <= r < 1.0)\n",
    "    wrong_count = sum(1 for r in all_rewards if -1.0 <= r < 0.0)\n",
    "    format_error_count = sum(1 for r in all_rewards if r < -1.0)\n",
    "    \n",
    "    # Log to W&B\n",
    "    wandb.log({\n",
    "        \"step\": step_count,  # Use step_count instead of batch.step\n",
    "        \"epoch\": batch.epoch,\n",
    "        \"avg_reward\": avg_reward,\n",
    "        \"max_reward\": max_reward,\n",
    "        \"min_reward\": min_reward,\n",
    "        \"correct_count\": correct_count,\n",
    "        \"idk_count\": idk_count,\n",
    "        \"wrong_count\": wrong_count,\n",
    "        \"format_error_count\": format_error_count,\n",
    "        \"total_trajectories\": len(all_rewards),\n",
    "    })\n",
    "    \n",
    "    print(f\"  Rewards: avg={avg_reward:.3f}, max={max_reward:.3f}, min={min_reward:.3f}\")\n",
    "    print(f\"  Correct: {correct_count}, IDK: {idk_count}, Wrong: {wrong_count}, Format Errors: {format_error_count}\")\n",
    "    \n",
    "    # Train on judged trajectories\n",
    "    await model.delete_checkpoints()\n",
    "    await model.train(\n",
    "        judged_groups,\n",
    "        config=art.TrainConfig(learning_rate=training_config[\"learning_rate\"]),\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Step {step_count} complete\\n\")\n",
    "    \n",
    "    step_count += 1\n",
    "    \n",
    "    # Stop after max_steps\n",
    "    if step_count >= training_config[\"max_steps\"]:\n",
    "        break\n",
    "\n",
    "run.finish()\n",
    "print(\"üéâ Training complete!\")\n",
    "print(f\"üìä View results: {run.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b06c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
